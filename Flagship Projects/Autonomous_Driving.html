<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">

    <title>IvLabs - Our Lab</title>
    <meta content="" name="description">
    <meta content="" name="keywords">

    <!-- Favicons -->
    <link href="../assets/img/favicon.png" rel="icon">
    <link href="../assets/img/apple-touch-icon.png" rel="apple-touch-icon">

    <!-- Google Fonts -->
    <link
        href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i"
        rel="stylesheet">

    <!-- Vendor CSS Files -->
    <link href="../assets/vendor/aos/aos.css" rel="stylesheet">
    <link href="../assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="../assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
    <link href="../assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
    <link href="../assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
    <link href="../assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

    <!-- Template Main CSS File -->
    <link href="../assets/css/style.css" rel="stylesheet">

    <!-- =======================================================
  * Template Name: Day
  * Updated: Jan 29 2024 with Bootstrap v5.3.2
  * Template URL: https://bootstrapmade.com/day-multipurpose-html-template-for-free/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>
    <!-- ======= Top Bar ======= -->
    <section id="topbar" class="d-flex align-items-center">
        <div class="container d-flex justify-content-center justify-content-md-between">
            <div class="contact-info d-flex align-items-center">
                <i class="bi bi-envelope-fill"></i><a href="mailto:contact@example.com">ivlabs@mec.vnit.ac.in</a>
                <i class="bi bi-phone-fill phone-icon"></i> +91 7078898155
            </div>
            <div class="social-links d-none d-md-block">
                <a href="https://twitter.com/teamivlabs" class="twitter"><i class="bi bi-twitter"></i></a>
                <a href="https://github.com/IvLabs" class="github"><i class="bi bi-github"></i></a>
                <a href="https://www.instagram.com/ivlabs/" class="instagram"><i class="bi bi-instagram"></i></a>
                <a href="https://in.linkedin.com/company/ivlabs-vnit" class="linkedin"><i
                        class="bi bi-linkedin"></i></i></a>
            </div>
        </div>
    </section>

    <!-- ======= Header ======= -->
    <header id="header" class="d-flex align-items-center">
        <div class="container d-flex align-items-center justify-content-between">

            <h1 class="logo"><a href="index.html">IvLabs</a></h1>
            <!-- Uncomment below if you prefer to use an image logo -->
            <!-- <a href="index.html" class="logo"><img src="../assets/img/logo.png" alt="" class="img-fluid"></a>-->

            <nav id="navbar" class="navbar">
                <ul>
                    <li><a class="nav-link scrollto active" href="../index.html#hero">Home</a></li>
                    <li><a class="nav-link scrollto" href="../index.html#about">Our Lab</a></li>
                    <!--<li><a class="nav-link scrollto" href="#services">Services</a></li>
          <li><a class="nav-link scrollto " href="#portfolio">Portfolio</a></li>-->
                    <li><a class="nav-link scrollto" href="../index.html#pricing">Projects</a></li>
                    <li><a class="nav-link scrollto" href="../index.html#team">Publications</a></li>
                    <li class="dropdown"><a href="#"><span>Our Team</span> <i class="bi bi-chevron-down"></i></a>
                        <ul>
                            <li><a href="#">Professor Incharge</a></li>
                            <li class="dropdown"><a href="#"><span>Alumni</span> <i class="bi bi-chevron-right"></i></a>
                                <ul>
                                    <li><a href="../alumni/batch-2014.html">Batch 2014</a></li>
                                    <li><a href="#">Batch 2015</a></li>
                                    <li><a href="../alumni/batch-2016.html">Batch 2016</a></li>
                                    <li><a href="../alumni/batch-2017.html">Batch 2017</a></li>
                                    <li><a href="#">Batch 2018</a></li>
                                    <li><a href="#">Batch 2019</a></li>
                                    <li><a href="#">Batch 2020</a></li>
                                    <li><a href="../alumni/batch-2021.html">Batch 2021</a></li>
                                    <li><a href="#">Batch 2022</a></li>
                                    <li><a href="#">Batch 2023</a></li>
                                </ul>
                            </li>
                            <li><a href="#">Core Coordinators</a></li>
                            <li><a href="#">Junior Year Coordinators</a></li>
                        </ul>
                    </li>
                    <li><a class="nav-link scrollto" href="#contact">Contact</a></li>
                </ul>
                <i class="bi bi-list mobile-nav-toggle"></i>
            </nav><!-- .navbar -->

        </div>
    </header><!-- End Header -->
    <main id="main">
        <section>
            <div class="section-title">
                <span>Autonomous Driving Platform</span>
                <h2>Autonomous Driving Platform</h2>
            </div>
            <div class="container position-relative" data-aos="fade-up" data-aos-delay="500">
                <h2>Overview:</h2>
                <p style="margin-bottom: 2px;;">This is the first version of IvLabs' autonomous driving platform. 
                    Built using the chassis of a racing grade 1/10th RC car, it can be used in outdoor road environments. 
                    It has additional sensors and components which enable perception, localization, planning and control for autonomous driving applications.</p>
                <p>The ongoing project for which this platform has been developed is 'Autonomous Delivery Robot', 
                    which aims to accomplish A to B navigation with obstacle avoidance within our institute campus.</p>  
                <h2>Mechanical Aspects</h2>
                <ul style="margin-left:30px;">
                    <li>The robot is based on a 1/10th scale RC car generally used in racing competitions.</li>
                    <li>It has hydraulic suspensions to make the motion smoother. It also has custom-built mounts and support structures for all sensors and controllers.</li>
                    <li>The dimensions are 40 cm x 33.5 cm x 32.5 cm and the total weight (including all components) is 5 kg.</li>
                </ul>
                <h2>Electric Drive and Steering</h2>
                <ul style="margin-left:30px;">
                    <li>While the robot originally used a miniature IC engine, it has been replaced by a <u><a href="https://robu.in/product/johnson-side-shaft-geared-motor-made-in-india-12-v-dc-150-rpm/?gclid=CjwKCAiAgqDxBRBTEiwA59eEN6vXhnMrDZ0y8UDPIEvUobdSR5x3hhATM4w4TiIxeI1z0-3rDndLgxoCDVYQAvD_BwE">
                        Johnson DC motor</a></u> as the main driver. The motor is connected to a transmission system which makes the robot 4WD (4 Wheel Drive). It is powered through a L298N motor driver.</li>
                    <li> The Ackermann steering is driven by a <u><a href="http://www.robotis.us/dynamixel-mx-28t/">Dynamixel MX-28</a></u> servo motor.</li>
                    <li>Both motors are driven by a 6S LiPo battery (22.2 V, 4500 mAh).</li>
                </ul>
                <h2>Sensors and Controllers</h2>
                <br><br>
                <img src="../assets\img\Flagship_Projects\Autonomous_driving\1.jpg" style="float:right;width:40%;height:400px;margin-right: 40px;;">
                <ul style="margin-left: 40px;">
                    <li><a href="https://orbbec3d.com/product-astra-pro/">Orbecc Astra Depth Camera</a> - RGBD camera mounted to get front view image and front 3D depth map for perception and planning. 
                        It has a range of 8 meters for the 3D depth map. Useful for localization (using visual odometry) and for identifying obstacles.</li>
                    <li><a href="https://www.ydlidar.com/products/view/5.html">YDLIDAR X4</a> - Laser range finder which gives a 2D (planar) 360 degrees depth map, used for perception and planning. 
                            It has a 10 meters scanning range. Useful for localization of robot and identifying obstacles.</li>
                    <li><a href="https://www.sparkfun.com/products/13762">SparkFun IMU Breakout MPU9250</a> - An inertial measurement unit (IMU). It consists of a 3-axis accelerometer, 
                        3-axis gyroscope, and a 3-axis magnetometer. Useful for localization of robot.</li>
                    <li><a href="https://robu.in/product/sharp-ir-distance-measuring-sensor-unit-4-30-cm-cable/?gclid=CjwKCAiAgqDxBRBTEiwA59eEN51hjqSDj3UtmiDmjivYpuAQnUocTmtRjiE5YnOLLp8DN_43S6akBRoCJpkQAvD_BwE">SHARP IR Sensor</a> -
                         A distance measuring sensor, to be used as the last line of defense against collisions. 
                        It has a range of 4-30 cm.</li>
                    <li><a href="https://www.u-blox.com/en/product/neo-m8-series">Neo-M8N GPS Module</a> - Gives global position (latitude, longitude and altitude) useful for global planning.</li>
                </ul>
                <br><br><br><br><br><br>
                <img src="../assets\img\Flagship_Projects\Autonomous_driving\2.jpg" style="float:left;width:40%;margin-left: 40px;">
                <ul style="float: right; width:50%"">
                    <li><a href="https://store.arduino.cc/usa/mega-2560-r3">Arduino Mega</a> - Used for lower-level control. It controls both the motors (main drive and steering), and handles all the sensors. 
                        It communicates with the main processor (Nvidia Jetson TX1) through <a href="http://wiki.ros.org/rosserial">rosserial</a> to get commands for the motors and to 
                        publish sensor data.</li>
                    <li><a href="https://developer.nvidia.com/embedded/jetson-tx1-developer-kit">Nvidia Jetson TX1</a> - Used for higher-level control. <a href="https://www.ros.org/">ROS</a> is used for communication between the various modules. It's Nvidia Maxwell GPU (256 CUDA cores) enables fast inference times for deep neural networks.
                        It runs all other processes like the global planning algorithm, the local planning algorithm, control algorithm, and so on.</li>
                    <li>All the sensors and controllers are powered by a 3S LiPo battery (11.1 V, 2200 mAh).</li>

                </ul>
                <br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
                <h2>Progress so far</h2>
                <strong>Semantic Segmentation</strong>
                <ul style="margin-left: 40px;">
                    <li>Implemented semantic segmentation model which uses RGB images from Astra and segments the road.</li>
                    <li>Implemented and trained <a href="https://arxiv.org/abs/1606.02147">EfficientNet (ENet)</a> on <a href="https://www.cityscapes-dataset.com/">Cityscapes</a> (coarse) dataset. 
                        Model generalizes well for local images without 
                        finetuning. <a href="https://github.com/akshaykvnit/autonomous-delivery-robot/tree/master/sem_seg_pytorch">Implementation</a> is done on PyTorch.</li>
                </ul>
                
                <img src="../assets\img\Flagship_Projects\Autonomous_driving\3.jpg">
                <br><br>
                <strong>360 degree Vision using Catadioptric Camera Setup</strong>
                <ul style="margin-left: 40px;">
                    <li>Catadioptric systems are those which make use of both lenses and mirrors for image formation. 
                        We propose the use of a conical mirror (reflector) and a single camera fixed over it's axis to achieve 360 degree vision.</li>
                    <li>Setup was simulated and results of cylindrical projection obtained are shown below.</li>
                    <li>This idea has been discontinued since manufacture of conical reflector is too difficult for us to get a reliable reflector 
                        without distortions on the surface. Whereas, it will be very expensive if outsourced (or must be manufactured in bulk).</li>
                </ul>
               <br><br>
               <img src="../assets\img\Flagship_Projects\Autonomous_driving\4.jpg" style="float:left;width:50%;height:auto;">
               <img src="../assets\img\Flagship_Projects\Autonomous_driving\5.jpg" style="float:right;width:50%;height:auto;">
               <strong><p style="padding:20px;text-size-adjust:20px;">Rectified Images (Cylindrical Projection)</p></strong> <br><br> <br><br>
               <h5>Mapping of VNIT campus</h5>
               <ul style="margin-left: 40px;">
                    <li>A Standard Definition (SD) Map of VNIT campus was created using OpenStreetMap (OSM).</li>
                    <li>It contains information about lanes, direction of the lane vectors, information about curbs, etc.</li>
               </ul>
               <br><br>
               <img src="../assets\img\Flagship_Projects\Autonomous_driving\6.jpg"><br>
               <h5>Global Planning</h5>
               <ul style="margin-left: 40px;">
                <li>For any 2 given GPS coordinates within the map, an optimal global path is generated using A* (A star) algorithm.</li>
                <li><a href="https://github.com/akshaykvnit/autonomous-delivery-robot/tree/master/Planning/Mission%20Planning">Implementation</a> is in Python.</li>
               </ul>
               <div style="display: flex;justify-content: center;"><br><br><img src="../assets\img\Flagship_Projects\Autonomous_driving\7.jpg"><br></div>
               <h2>Localization and controls</h2>
               <ul style="margin-left: 40px;">
                <li><strong> Localization:</strong> of the robot is based on a combination of pose data from GPS module, 
                    IMU sensor, LIDAR (ICP odometry) and RTABMap visual odometry (from Astra depth sensor), using an Extended Kalman Filter (EKF).</li>
                <li><strong>Controls :</strong><a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=2ahUKEwjc0Y7e65vnAhWc6nMBHcWADtUQFjABegQIAhAB&url=https%3A%2F%2Fwww.ri.cmu.edu%2Fpub_files%2Fpub3%2Fcoulter_r_craig_1992_1%2Fcoulter_r_craig_1992_1.pdf&usg=AOvVaw2Aysy83x-mx8S-Pg34hWim"> Pure pursuit algorithm</a> 
                    is used to produce control signals required for the transition between the waypoints generated by the local planner.</li>
               </ul>
               <h2>Obstacle avoidance</h2>
               <ul style="margin-left: 40px;">
                <li><strong>Local Planning :</strong> Along with the global plan, the 2D cost map generated from LIDAR and the segmented map of road is used to check collisions. Collisions are checked using a circle-point method by sampling the global plan for a given time horizon. 
                    The local plan is then generated to avoid collisions while balancing the cost of deviation from global plan. </li>
               </ul>
               <h2>Team</h2>
                <a href="http://unmeshp.weebly.com/">Unmesh Patil<br></a>
                Aniket Gujarathi<br>
                <a href="https://akshayk07.weebly.com/">Akshay Kulkarni<br></a>
                Yogesh Phalak<br>
                Rajeshree Deotalu<br>
                <a href="http://navidpanchi.tech/">Navid Panchi<br></a>
                Aman Jain<br>
                Himanshu Patil<br>
                <h2>Mentors</h2>
                <a href="http://mec.vnit.ac.in/people/sschiddarwar/">Dr. Shital S. Chiddarwar</a> and <a href="http://eee.vnit.ac.in/people/adhabale/">Dr. Ashwin S. Dhabale</a>

        
            </div> 
        </section>
            
            

    </main>
    <footer id="footer">

        <div class="container">
            <div class="copyright">
                &copy; Copyright <strong><span>IvLabs</span></strong>. All Rights Reserved
            </div>
            <div class="credits">
                <!-- All the links in the footer should remain intact. -->
                <!-- You can delete the links only if you purchased the pro version. -->
                <!-- Licensing information: https://bootstrapmade.com/license/ -->
                <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/day-multipurpose-html-template-for-free/ -->
                Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
            </div>
        </div>
    </footer><!-- End Footer -->

    <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i
            class="bi bi-arrow-up-short"></i></a>
    <div id="preloader"></div>

    <!-- Vendor JS Files -->
    <script src="../assets/vendor/aos/aos.js"></script>
    <script src="../assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
    <script src="../assets/vendor/glightbox/js/glightbox.min.js"></script>
    <script src="../assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
    <script src="../assets/vendor/swiper/swiper-bundle.min.js"></script>
    <script src="../assets/vendor/php-email-form/validate.js"></script>

    <!-- Template Main JS File -->
    <script src="../assets/js/main.js"></script>

</body>

</html>